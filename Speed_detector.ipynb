{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6117c3c9-c3a1-495b-aacd-63e4963a4fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import easyocr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74704ded-6d94-4b7d-bb09-9dec0ff1656c",
   "metadata": {},
   "source": [
    "<H1>SPEED DETECTOR BOARDS RECOGNIZED USING CV2 AND ORB MODELS AVAILABLE<H1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def6fe36-23aa-4b74-b695-317b2474c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c2552f-2d6a-46a3-9d46-9728e66ad32a",
   "metadata": {},
   "source": [
    "<P>DEFINING THE TEMPLATE DIRECTORIES AND MILESTONES CONTAINING SPEED DETECTORS</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8638599-9810-4675-9c73-d4fee138a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_dir = './DataSet/Template images'\n",
    "mile1_path='./DataSet/Milestone 1'\n",
    "mile2_path='./DataSet/Milestone 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f80bbaa-d5a7-462f-82e2-7351998622f5",
   "metadata": {},
   "source": [
    "<p>GET SPEED BOARD FUNCTION FOR GETTING THE SPEED WITH THE TEMPLATE using template matching features,Pre-processing the image by tilt angles and contrast brightness</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "45546754-9ec4-4519-a471-9a88d2569e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speed_board(template_dir,mile_path,filename):\n",
    "    # Load the target image and preprocess\n",
    "    target_path = os.path.join(mile_path, filename)\n",
    "    img2 = cv2.imread(target_path, 0)  # Target image\n",
    "    target_width = 800\n",
    "    img2 = cv2.resize(img2, (target_width, int(img2.shape[0] * target_width / img2.shape[1])))\n",
    "    \n",
    "    # Sharpening kernel\n",
    "    kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])\n",
    "    img2 = cv2.filter2D(img2, -1, kernel)\n",
    "    image_brightness = np.mean(img2)\n",
    "    image_contrast = np.std(img2)\n",
    "    \n",
    "    # Initialize the ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "    \n",
    "    best_match = []\n",
    "    best_img_match = None\n",
    "    best_template_name = None\n",
    "    best_avg_distance = float('inf')\n",
    "    \n",
    "    # Iterate over all templates\n",
    "    for template_name in os.listdir(template_dir):\n",
    "        template_path = os.path.join(template_dir, template_name)\n",
    "        img1 = cv2.imread(template_path, 0)  # Template image\n",
    "        \n",
    "        if img1 is None:\n",
    "            continue\n",
    "        \n",
    "        # Preprocess the template image\n",
    "        img1 = cv2.filter2D(img1, -1, kernel)\n",
    "       \n",
    "    \n",
    "        # Find the keypoints and descriptors with ORB\n",
    "        kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "        kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "        \n",
    "        if des1 is None or des2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Create a BFMatcher object and match descriptors\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(des1, des2)\n",
    "        # Sort matches by distance\n",
    "        matches = sorted(matches, key=lambda x: x.distance)\n",
    "        \n",
    "        # Extract matched keypoints\n",
    "        points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "        \n",
    "        for i, match in enumerate(matches):\n",
    "            points1[i, :] = kp1[match.queryIdx].pt\n",
    "            points2[i, :] = kp2[match.trainIdx].pt\n",
    "        \n",
    "        # Find homography\n",
    "        h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n",
    "        \n",
    "        # Warp the template image to align with the target image\n",
    "        height, width = img2.shape\n",
    "        aligned_template = cv2.warpPerspective(img1, h, (width, height))\n",
    "        \n",
    "        # Apply the sharpening filter to the aligned template\n",
    "        aligned_template = cv2.filter2D(aligned_template, -1, kernel)\n",
    "        \n",
    "        # Find the keypoints and descriptors with ORB for the aligned template\n",
    "        kp1_aligned, des1_aligned = orb.detectAndCompute(aligned_template, None)\n",
    "        \n",
    "        if des1_aligned is None or des2 is None:\n",
    "            continue\n",
    "        \n",
    "        # Match descriptors again with the aligned template\n",
    "        matches_aligned = bf.match(des1_aligned, des2)\n",
    "        \n",
    "        # Sort matches by distance\n",
    "        matches_aligned = sorted(matches_aligned, key=lambda x: x.distance)\n",
    "        template_brightness = np.mean(img1)\n",
    "        template_contrast = np.std(img1)\n",
    "        if image_contrast != 0:\n",
    "        # Adjust contrast\n",
    "            img2_brighted = (template_contrast / image_contrast) * (img2 - image_brightness) + template_brightness\n",
    "        else:\n",
    "            img2_brighted = img2.copy()\n",
    "        img2_brighted = np.clip(img2_brighted, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        # Find the keypoints and descriptors with ORB for the aligned template\n",
    "        kp2_aligned, des2_aligned = orb.detectAndCompute(img2_brighted, None)\n",
    "        \n",
    "        if des2_aligned is None or des1_aligned is None:\n",
    "            continue\n",
    "        # Match descriptors again with the aligned template\n",
    "        matches_aligned2 = bf.match(des1_aligned, des2_aligned)\n",
    "        \n",
    "        # Sort matches by distance\n",
    "        matches_aligned2 = sorted(matches_aligned2, key=lambda x: x.distance)\n",
    "        # Calculate average distance of matches\n",
    "        avg_distance = np.mean([match.distance for match in matches_aligned2])\n",
    "        \n",
    "        # Update the best match if current matches are better\n",
    "        if avg_distance>60:\n",
    "            continue\n",
    "        if avg_distance < best_avg_distance:\n",
    "            best_match = matches_aligned\n",
    "            best_template_name = template_name\n",
    "            best_avg_distance = avg_distance\n",
    "            best_img_match = cv2.drawMatches(aligned_template, kp1_aligned, img2_brighted, kp2_aligned, matches_aligned2, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "    \n",
    "    # Show the matches\n",
    "    result=\"\"\n",
    "    if best_img_match is not None:\n",
    "        print(f\"Best matching template: {best_template_name} with avg distance: {best_avg_distance}\")\n",
    "        cv2.imshow(\"Best Matches\", best_img_match)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        result+=best_template_name\n",
    "    else:\n",
    "        result+=\"None\"\n",
    "        print(\"No good match found.\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fe5c7-cdc5-47c3-85fd-7608c63fd47d",
   "metadata": {},
   "source": [
    "<p>To get the picture and the speed dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13aa69c-e39e-4fbd-8996-d35e8cd2391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataSet(mile_path):\n",
    "    datas=[]\n",
    "    for filename in os.listdir(mile_path):\n",
    "        template=get_speed_board(template_dir,mile_path,filename)\n",
    "        print(template)\n",
    "        if(template != \"None\"):\n",
    "            speed=template.replace(\"Template-\",\"\").replace(\".jpg\",\"\").replace(\".PNG\",\"\")\n",
    "        else:\n",
    "            speed=template\n",
    "        data=[]\n",
    "        data.append(filename)\n",
    "        data.append(speed)\n",
    "        datas.append(data)\n",
    "    return datas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f078601c-4229-4cf1-9abd-bcee04b835a1",
   "metadata": {},
   "source": [
    "<P>let's get the dataset for every milepath and convert to <b>Dataframe using pandas</b></P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "12c3bdb4-8a41-4bce-bed6-fc842f7c71d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best matching template: Template-45.jpg with avg distance: 37.88333333333333\n",
      "Template-45.jpg\n",
      "Best matching template: Template-50.jpg with avg distance: 42.78151260504202\n",
      "Template-50.jpg\n",
      "Best matching template: Template-85.jpg with avg distance: 43.92888888888889\n",
      "Template-85.jpg\n",
      "Best matching template: Template-85.jpg with avg distance: 46.41232227488152\n",
      "Template-85.jpg\n",
      "No good match found.\n",
      "None\n",
      "Best matching template: Template-40.jpg with avg distance: 53.43715846994535\n",
      "Template-40.jpg\n",
      "Best matching template: Template-15.jpg with avg distance: 48.902061855670105\n",
      "Template-15.jpg\n",
      "Best matching template: Template-70.jpg with avg distance: 50.18222222222222\n",
      "Template-70.jpg\n",
      "Best matching template: Template-25.jpg with avg distance: 44.70472440944882\n",
      "Template-25.jpg\n",
      "Best matching template: Template-55.jpg with avg distance: 53.52427184466019\n",
      "Template-55.jpg\n",
      "Best matching template: Template-50.jpg with avg distance: 41.53639846743295\n",
      "Template-50.jpg\n",
      "Best matching template: Template-85.jpg with avg distance: 46.83168316831683\n",
      "Template-85.jpg\n",
      "No good match found.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "mile1_output=get_dataSet(mile1_path)\n",
    "mile2_output=get_dataSet(mile2_path)\n",
    "columns=[\"INPUT IMAGE\",\"SPEED LIMIT\"]\n",
    "df1=pd.DataFrame(mile1_output,columns=columns)\n",
    "df2=pd.DataFrame(mile2_output,columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b5f1eb-715f-47e6-a505-5b98302f0b64",
   "metadata": {},
   "source": [
    "<H2>CONVERTING TO CSV OUTPUT FILE RESULT</H2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1957075c-50bd-47b0-a8b4-f9761b8f00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"M1_2_OUTPUT.csv\",index=False)\n",
    "df2.to_csv(\"M2_OUTPUT.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487fce1-90a3-493f-96f6-4b4dcf3675ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
